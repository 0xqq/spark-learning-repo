// Reference: https://github.com/apache/spark/blob/5264164a67df498b73facae207eda12ee133be7d/streaming/src/main/scala/org/apache/spark/streaming/receiver/BlockGenerator.scala

package org.apache.spark.streaming.receiver 

import java.util.concurrent.{ArrayBlockingQueue, TimeUnit}
import scala.collection.mutable.ArrayBuffer 
import org.apache.spark.{SparkConf, SparkException}
import org.apache.spark.internal.Logging 
import org.apache.spark.storage.StreamBLockId 
import org.apache.spark.streaming.util.RecurringTimer 
import org.apache.spark.util.{Clock, SystemClock}


// --- 这里的代码阅读顺序建议先阅读 BlockGenerator 类中的对 5 中状态的注释信息, 了解不同状态都会执行那些方法 ---
// --- 在了解 5 中状态, 5 中状态下执行的不同操作后, 再来阅读 BlockGeneratorListener 中所定义的不同方法所触发/回调的时机, 会有更好的理解 --- 





// ---- class of BlockGeneratorListener --- 

// Listener object for BlockGenerator events 
// BlockGenerator 中会生成不同类型的 Event, 不同类型的 Event 会触发执行不同的回调函数,
// 为了防止 Event 排队, 所以在这里采用的并非是线程池 + 队列, 而是采用事件驱动的方式来响应各种 event
// --
// 其中 BlockGenerator 负责生成不同的 event, 而不同的 event 会回调不同的方法, 
// 也就是 BlockGeneratorListener 会监听 event, 根据不同的 event 会调用不同的方法,
// 这种事件驱动机制也同样应用在 SparkListenerBus 和 SparkListener 之间, 其中 SparkListenerBus 负责接收 Spark 发给它的 event
// 根据 Event 类型的不同调用 SparkListener trait 中不同的回调方法, 而 SparkListener 中仅给监听不同 Event 回调函数的定义
// 具体逻辑实现由继承 SparkListener 的子类来完成
// --
// zookeeper 上的对不同路径节点所设定的 Watcher 的调用方法也和这里的事件驱动方式类似, 只不过 ZK 上 Watcher 所监听的事件控制在监听路径的,增,删,改,查 这四种状态

private[streaming] trait BlockGeneratorListener {

    // Call after a data item is added into the BlockGenerator.
    // 当 BlockGenerator 中加入数据项时, BlockGeneratorListener 中的 onAddData 这个函数会作为该事件的回调函数而被调用.

    // The data addition and this callback are synchronized with the block generation and its associated callback,
    // so block generation waits for the active data addition+callback to complete. 
    // BlockGenerator 中数据项增加操作, 及该操作所触发的回调函数与生成数据块/block 操作, 及该操作所触发的一系列回调方法的执行时串行的关系,
    // 所以, 知道所有的数据项增加操作及该操作触发的回调方法全部执行完毕, 数据块/block 才能创建完成. 

    // This is useful for updating metdata on successful buffering of a data item, 
    // specificially that metadata that will be useful when a block is generated.
    // onAddData 方法对于更新描述尚在缓冲区中的数据项的元数据信息十分有用, 
    // 尤其是对于那些需要参照元数据中的信息的数据块. 

    // Any long blocking operation in this callback will hurt the throughput.
    // onAddData 回调方法中任何长时间的阻塞操作, 都会对整个流系统的吞吐性能造成重大影响. 
    def onAddData(data:Any, metadata:Any):Unit 


    // Called when a new block of data is generated by the block generator. 





}


// -----  class of BlockGenerator ----- 
/**
  Generates batches of objects received by a [[org.apache.spark.streaming.receiver.Receiver]] and puts them into appropriately
  named blocks at regular intervals.
  按照一定时间间隔将从 [[org.apache.spark.streaming.receiver.Receiver]] 多个 batch 接收到的对象汇聚在一起构建成数据块.
  (原来 1 个batch 接收到的数据对象未必构建 1 个 block, 多少个 batch 构建一个 block 对象, 这个是由设定的 block.interval 这个参数来决定的.
  从之前阅读反压(backpressure) 这个设计文档来看, 这个 regular interval 应该就是参数 block.interval 这个可由 spark-conf 传参设定的数值)
  所以, 应该是 1 block.interval = [1 - n 个 batch] , 1 block = [1 - n 个 block.interval 周期内接收到的 object 集合构成]

  This class starts two threads, one to periodically start a new batch and prepare the previous batch of as a block,
  the other to push the blocks into the block manager. 
  BlockGenerator 类中会启动 2 个线程, 一个负责周期性地开启读取新 batch/处理批次到达的数据, 然后将先前 batch/处理批次到达的数据构建成 1 个 block,
  另一个线程则负责将 1 到多个 block 推送到 block manager 中, 把不同批次达到的数据所构建的 block/数据块托管到 BlockManager 对象中去.
   

  Note: Do not create BlockGenerator instances directly inside receivers.
  Use `ReceiverSupervisor.createBlockGenerator` to create a BlockGenerator and use it. 
  需要注意的是: 不要在 receiver 中直接 new BlockGenerator 来创建实例对象. 
  使用 ReceiverSupervisor.createBlockGenerator 方法来创建 BlockGenerator 实例, 然后调用其方法.
*/
private[streaming] class BlockGenerator (
	listener:BlockGeneratorListener,  // 此处所传入的是实现了 BlockGeneratorListener 中所描述的方法的实体类对象
	receiverId:Int, 
	conf:SparkConf,
	clock:Clock = new SystemClock() // 构建系统时钟对象
	) extends RateLimiter(conf) with Logging {
	 // 这里的 RateLimiter 是用于控制 Spark 作为上游数据流的消费订阅者消费速率的类, 其构造函数中
	 // 需要传入 SparkConf 实例, 通过加载该实例中的 'spark.streaming.receiver.maxRate' 
	 // 这个参数中的数值, 来作为限流的参数, 这个是速率  rate,
	 // rate * block.interval = 一个周期内 spark streaming 所接收到的数据条数,也就是,数据密度(单位时间到达数据条数)
     
     // Block 是由一个 StreamBlockId 作为该 Block 的唯一标识, 和一块内存缓冲数据块构成
     private case class Block(id:StreamBlockId, buffer:ArrayBuffer[Any])

     // The BlockGenerator can be in 5 states, in the order as follows: 
     // BlockGenerator 是一个包含 5 个状态的状态机, (不过状态机的状态切换逻辑并不复杂) 5 种状态是依次按顺序切换的, 描述如下: 
     // ----
     // Q: 状态机, Event, 监听/Listener 这 3 者是怎样的调用关系? 
     // ---- 
     // - Initialized: 初始状态, 开始阶段什么都不执行
     
     // - Active: start() has been called, and it is generating blocks on added data.
     // - 活跃状态: start() 方法已经被调用, 开始基于从上游不断加载进来的数据生成数据块/block 

     // - StoppedAddingData: stop() has been called, the adding of data has been stopped, but blocks are still being generated and pushed. 
     // - 停止加载上游数据状态: stop() 这个方法被调用了, 已经停止从上游数据加载数据, 但是数据块还在不断生成, 并将生成完毕的数据块推送到 BlockManager 中, 交付给 BlockManager 管理. 

     // - StoppedGeneratingBlocks: Generating of blocks has been stopped, but they are still being pushed. 
     // - 停止构建数据块状态: 数据块的构建被停止, 但是被构建的数据块仍可以逐个被推送到 BlockManager 端. 

     // - StoppedAll: Everything has been stopped, and the BlockGenerator object can be GCed. 
     // - 终止所有操作状态: 所有操作均被终止, 这个时候 BlockGenerator 对象实例所占用的资源可通过 GC 垃圾回收方法回收释放.

     // 在这里创建一个枚举类型, 来标识 5 个不同的状态
     private object GeneratorState extends Enumeration {
         type GeneratorState = Value 
         val Initialized, Active, StoppedAddingData, StoppedGeneratingBlocks, StoppedAll = Value 
     }

     import GeneratorState._ 

     // 从传入的参数  conf:SparkConf 中加载 block.interval 这个配置项的数值, 如果没有设置则返回 200ms 这个数值
     // 这个也就是前文注释中提到的 block.interval 这个参数的全称了
     private val blockIntervalMs = conf.getTimeAsMs("spark.streaming.blockInterval", "200ms") 
     
     // 到这里再次确认下 block.interval 这个数值为正, 否则打出提示信息
     require(blockIntervalMs > 0, s"'spark.streaming.blockInterval' should be a positive value")
     
     // 这个方法比较有意思, RecurringTimer 的功能类似于一个触发器, 传入系统基准时间 clock
     // 和触发时间间隔 blockIntervalMs, 以及触发执行的方法 updateCurrentBuffer 
     // 最后是为这个触发器命名的字符串, 全部赋值好后, 将会以 clock 这个时间为起始时间
     // 每隔 $blockIntervalMs 时间间隔, 定期触发一次 updateCurrentBuffer 这个方法
     // --- 
     // 而仔细看下这个 RecurringTimer 类的话, 会发现其中就是周期性地启动 1 个线程来执行 updateCurrentBuffer 函数的逻辑
     // 而这个线程, 也就是一开始注释信息中提到的, 周期性接收 batch 数据, 然后构建 block 的这个线程了: 
     // "This class starts two threads, one to periodically start a new batch and prepare the previous batch of as a block"
     private val blockIntervalTimer = 
         new RecurringTimer(clock, blockIntervalMs, updateCurrentBuffer, "BlockGenerator")

     // 这个参数加载方式和上述的 block.interval 参数的加载方式一样, 从配置文件中读取队列长度数值
     private val blockQueueSize = conf.getInt("spark.streaming.blockQueueSize", 10)

     // 根据配置项中的队列长度数值来创建对应长度的队列, 队列中存放的元素是 Block 类型的
     private val blockForPushing = new ArrayBlockingQueue[Block](blockQueueSize)

     // 而这个是, 前文提交到的另一个线程, 那个将 block 不断推送给 BlockManager 的线程
     // 线程中执行的方法是 keepPushingBlocks 
     private val blockPushingThread = new Thread { override def run() { keepPushingBlocks() } }

     
     // 这个用 volatile 修饰的 currentBuffer 对它执行的写操作, 是直接落到 RAM 空间上的, 而之所以使用 volatile 关键字来修饰该变量
     // 目的是防止,多个线程操作这个对象, 一个线程对该对象执行 update 更新其中数值的时候, 变动发生在内存, 这样对其进行访问的另一个线程
     // 所获取到的这个变量的数值还停留在原先的没更新的数值, 造成这种数据不一致
     // 而有了 @volatile 这个关键字, 对数值的操作会直接更新在 RAM 上的, 占用同一块空间的所有线程都能立即察觉到数值的瞬时变动
     @volatile private var currentBuffer = new ArrayBuffer[Any]
     @volatile private var state = Initialized 

     // Start block generating and pushing threads 
     // 启动 2 个线程, 一个用来周期性触发构建 block, 另一个将本地构建好的 block pushing 到 BlockManager 
     def start():Unit = synchronized {
     	// start 状态转换的入口条件必须是, 状态为 Initialized 才能够进入到 start() 方法内
     	// 否则便会报错抛异常: 当状态为非 Initialized 时, 无法进入 BlockGenerator start 函数
     	if ( state == Initialized) {
     		// 首先成功进入方法后, 最先将状态置位 Active 状态
     		state = Active

     		// 然后, 启动周期性生成 block 触发器线程
     		blockIntervalTimer.start() 
     		// 和推送 block 到 BlockManager 的线程
     		blockPUshingThread.start() 

     		// 打印日志, BlockGenerator 启动了
     		logInfo("Started BlockGenerator")
     	} else {
     		// 否则, 状态不满足无法执行 start 函数
     		throw new SparkException(
     			s"Cannot start BlockGenerator as its not in the Initialized state [state = $state]")
     	}
     }


     // Stop everything in the right order such that all the data added is pushed out correctly.
     // 顺序停掉所有操作, 例如对于, 上游数据流加载, 和 block 的推送操作, 必须按照顺序先停掉上游数据加载这里的操作,
     // 然后, 将最后的数据构建成 block 推送到 BlockManager 之后, 再停止整个的数据推送操作
     // (因为颠倒顺序的话, 会出现数据滞留本地, 没有被推送到 BlockManager 的情况, 造成数据丢失等错误)
     // ---
     // - First, stop adding data to the current buffer . 
     // - 首先, 停到将上游数据不断写入本地缓冲区的操作.
     // ---
     // - Second, stop generating blocks. 
     // - 然后, 停掉构建数据块这样操作.
     // ---
     // - Finally, wait for queue to-be-pushed blocks to be drained. 
     // - 最后, 等待推送线程将所有等待推送的 block 所在的队列中的所有 block 全部推送完毕. 即将滞留在队列中的数据全部推送到 BlockManager 端. 
     def stop():Unit ={
     	// Set the state to stop adding data 
     	synchronized {
     		// stop 入口处判断状态, 非 Active 状态无法进入到 stop 方法中
     		if ( state == Active ) {
     			state = StoppedAddingData 
     		} else {
     			logWarnings(s"Cannot stop BlockGenerator as its not in the Active state [state =$state]")
     		}
     	} 
     	// 在这里我们发现的是, 但凡是对 state 进行判断和变更的时候, 都使用同步代码块将代码包起来, 
     	// 这么做的目的应该是防止多个线程同时执行 stop/ start 方法对其中状态修改生成脏数据状态信息造成状态机状态切换出现问题 

     	// Stop generating blocks and set the state for block pushing thread to start draining the queue 
     	// 停到构建数据块操作, 然后进行状态切换, 来让数据块推送线程开始推送队列中所有的 Block 到 BlockManager 

        // 打印日志
     	logInfo("Stopping BlockGenerator")

     	// 以非中断的防止将触发器中执行的操作执行完
     	blockIntervalTimer.stop( interruptTimer = false )

        // 将状态置位 StoppedAll 
     	synchornized { state = StoppedAll }

     	// 打印日志, 将 BlockGenerator 停止服务的日志打印出来, 这个 stop 方法中进行了 2 此状态切换
     	logInfo("Stopped BlockGenerator")
     }  
}




















// ---- 阅读之前写的 ---- 

// 在阅读完作者自己实现的加持各种可靠, 无丢失 buff 的 ReliableKafkaReceiver.scala 之后, 发现这个类中很多方法
// 都是各种处理 Block 和 Seq[topic.partition-offset] 二者的关联映射关系, 
// 我在这里其实并不是很清楚为什么每次在构建映射关系的时候,为何要将缓存 key:topic.parition, value:offset 关系的 hash map 给清空, 
// 也就是下面注释的这段代码中最后的 clear 方法调用清空 hash map 
/**

// Remember the current offset for each topic and partition. 
// This is called when a block is generated .
private def rememberBlockOffsets(blockId:StreamBlockId):Unit = {
	// Get a snapshot of current offset map and store with related block id. 
	val offsetSnapshot = topicPartitionOffsetMap.toMap 
	blockOffsetMap.put(blockId, offsetSnapshot)
	topicPartitionOffsetMap.clear() // why clean the contents in hash map here ? 
}
*/
// 虽然我觉得是, 上游 Receiver 基类在构建 block 的时, 是按照整个系统中的 block.interval 构建周期, 周期性地读取数据并构建,
// 每次存放到 hash map 中的 topic,partition - offset 仅仅是一个 block.interval 时间周期的数据信息, 因为这个 block.interval 完成, 数据入 block, 
// 建立这个 block 的 block id 与 多个 topic.partition 的 offset 之后, 清空 topic.partition offset 的 hash map 缓存, 
// 好等待下个 block.interval 新数据到来好记录新到达的多个 batch 中从 kafka 拉取的 topic.partition - offset 的数据关系对 ? 
// 后来想了一下, 是因为我对调用 rememberBlockOffsets 函数的 BlockGeneratorListener 中定义的回调函数: onGenerateBlock 
// 这个回调函数所处理的 Event 到达的时机不理解, 导致我不清楚 rememberBlockOffsets 函数被执行的时间背景是什么样的, 
// 进而导致了我对其中缓存 hash map 中数据 clear 清空方法的不了解, 所以这里决定阅读批注一下 BlockGenerator.scala 这一份源码

